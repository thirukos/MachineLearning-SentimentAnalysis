{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install cleantext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sarathkumar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\sarathkumar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\sarathkumar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\sarathkumar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from cleantext import clean\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set file path\n",
    "input_file_path = 'D:\\\\TCD\\\\Term1\\\\CS7CS4 - ML\\\\group project\\\\MachineLearning-group-project\\\\RawDatasets\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data set\n",
    "df = pd.read_csv(input_file_path + 'tweets_india.csv', usecols=['content'])\n",
    "# df['Origin'] = 'southasia'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------\n",
      "Dataset content\n",
      "-------------------\n",
      "                                             content\n",
      "0  Have a nice night trip with T \\r\\nUK to Delhi....\n",
      "1  May her soul RIP. As a nation we are with the ...\n",
      "2  @SanjayAzadSln ‡§Ö‡§§‡•ç‡§Ø‡§Ç‡§§ ‡§¶‡•Å‡§ñ‡§¶ ‡§¶‡§ø‡§µ‡§Ç‡§ó‡§§ ‡§Ü‡§§‡•ç‡§Æ‡§æ ‡§ï‡•ã ‡§∂‡•ç‡§∞...\n",
      "3  @firki07 Firki with queen üò≠ https://t.co/mhvgH...\n",
      "4  @TuckerCarlson This so called great Britain lo...\n",
      "-------------------\n",
      "Length of data set:  932\n",
      "Shape of data set:  (932, 1)\n",
      "-------------------\n",
      "Dataset information\n",
      "-------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 932 entries, 0 to 931\n",
      "Data columns (total 1 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   content  932 non-null    object\n",
      "dtypes: object(1)\n",
      "memory usage: 7.4+ KB\n"
     ]
    }
   ],
   "source": [
    "print('-------------------')\n",
    "print('Dataset content')\n",
    "print('-------------------')\n",
    "print(df.head())\n",
    "print('-------------------')\n",
    "# Some information about the data set\n",
    "print('Length of data set: ', len(df))\n",
    "print('Shape of data set: ', df.shape)\n",
    "\n",
    "print('-------------------')\n",
    "print('Dataset information')\n",
    "print('-------------------')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for null values - needs to be zero\n",
    "np.sum(df.isnull().any(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>have a nice night trip with t \\r\\nuk to delhi....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>may her soul rip. as a nation we are with the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@sanjayazadsln ‡§Ö‡§§‡•ç‡§Ø‡§Ç‡§§ ‡§¶‡•Å‡§ñ‡§¶ ‡§¶‡§ø‡§µ‡§Ç‡§ó‡§§ ‡§Ü‡§§‡•ç‡§Æ‡§æ ‡§ï‡•ã ‡§∂‡•ç‡§∞...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@firki07 firki with queen üò≠ https://t.co/mhvgh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@tuckercarlson this so called great britain lo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content\n",
       "0  have a nice night trip with t \\r\\nuk to delhi....\n",
       "1  may her soul rip. as a nation we are with the ...\n",
       "2  @sanjayazadsln ‡§Ö‡§§‡•ç‡§Ø‡§Ç‡§§ ‡§¶‡•Å‡§ñ‡§¶ ‡§¶‡§ø‡§µ‡§Ç‡§ó‡§§ ‡§Ü‡§§‡•ç‡§Æ‡§æ ‡§ï‡•ã ‡§∂‡•ç‡§∞...\n",
       "3  @firki07 firki with queen üò≠ https://t.co/mhvgh...\n",
       "4  @tuckercarlson this so called great britain lo..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Converting all text to lower case\n",
    "def convert_to_lower_case(data_set):\n",
    "    data_set['content'] = data_set['content'].str.lower()\n",
    "\n",
    "convert_to_lower_case(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop word list:\n",
      "----------------\n",
      "{'myself', 'herself', \"it's\", 'very', 'won', 'over', 'those', 'be', \"couldn't\", 'between', \"you'll\", 's', 'both', 'he', 'hers', 'out', 'haven', 'being', \"doesn't\", \"isn't\", 'can', 'with', 'about', \"should've\", 'am', 'which', 'are', 'had', \"don't\", \"she's\", 'where', 'shan', 'they', 'the', 'some', 'it', 'only', 'by', 'off', 'she', 'theirs', \"you've\", 'himself', 'not', \"hadn't\", 've', 'wouldn', 'will', 'i', 'shouldn', 'below', 'what', 'didn', 'hadn', 'yours', 'any', 'there', \"that'll\", 'on', 'his', 'all', 'themselves', 'further', 'than', 'into', 'her', 'our', 'm', 'through', 'for', 'isn', 'no', 'against', 'ours', 'we', \"shan't\", 'mightn', 'each', 'and', 'll', 'don', 'at', 'why', \"mightn't\", \"shouldn't\", 'here', 'too', 'my', 'yourself', \"mustn't\", 'do', 'their', 'during', 'other', 'weren', 'him', 'once', 'were', 'this', 'while', 'own', 'ain', 'them', 'been', 'then', 'itself', 'did', 'up', 'aren', 'mustn', 'doing', 'ma', 're', 'wasn', 'or', 'but', \"hasn't\", 'because', 'these', 'is', 'o', \"didn't\", 'so', 'under', 'few', 'have', \"you'd\", 'its', 'me', 'who', 'does', 'of', 'same', 'when', \"wouldn't\", \"aren't\", \"haven't\", \"needn't\", 'having', 'until', 'you', 'in', 'most', 'nor', 'after', 'just', 'if', 'from', 'y', 'was', 'that', 'your', 'has', \"you're\", 'yourselves', 'needn', \"weren't\", 'doesn', 'more', 'hasn', 'to', 'whom', 't', \"wasn't\", 'an', 'ourselves', 'again', 'above', 'such', 'before', 'how', 'now', \"won't\", 'd', 'couldn', 'should', 'as', 'down', 'a'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nice night trip uk delhi. üòçüòçüòç https://t.co/7am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>may soul rip. nation family fellow uk citizens...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@sanjayazadsln ‡§Ö‡§§‡•ç‡§Ø‡§Ç‡§§ ‡§¶‡•Å‡§ñ‡§¶ ‡§¶‡§ø‡§µ‡§Ç‡§ó‡§§ ‡§Ü‡§§‡•ç‡§Æ‡§æ ‡§ï‡•ã ‡§∂‡•ç‡§∞...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@firki07 firki queen üò≠ https://t.co/mhvgh7aqsc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@tuckercarlson called great britain looted 45 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content\n",
       "0  nice night trip uk delhi. üòçüòçüòç https://t.co/7am...\n",
       "1  may soul rip. nation family fellow uk citizens...\n",
       "2  @sanjayazadsln ‡§Ö‡§§‡•ç‡§Ø‡§Ç‡§§ ‡§¶‡•Å‡§ñ‡§¶ ‡§¶‡§ø‡§µ‡§Ç‡§ó‡§§ ‡§Ü‡§§‡•ç‡§Æ‡§æ ‡§ï‡•ã ‡§∂‡•ç‡§∞...\n",
       "3     @firki07 firki queen üò≠ https://t.co/mhvgh7aqsc\n",
       "4  @tuckercarlson called great britain looted 45 ..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Removing stop words (un-necessary words) - using nltk's pre-defined stop words\n",
    "STOP_WORDS = set(stopwords.words('english'))\n",
    "print('Stop word list:')\n",
    "print('----------------')\n",
    "print(STOP_WORDS)\n",
    "\n",
    "def remove_stop_words(content):\n",
    "   return \" \".join([text for text in str(content).split() if text not in STOP_WORDS])\n",
    "\n",
    "df['content'] = df['content'].apply(lambda content: remove_stop_words(content=content))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nice night trip uk delhi. üòçüòçüòç</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>may soul rip. nation family fellow uk citizens...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@sanjayazadsln ‡§Ö‡§§‡•ç‡§Ø‡§Ç‡§§ ‡§¶‡•Å‡§ñ‡§¶ ‡§¶‡§ø‡§µ‡§Ç‡§ó‡§§ ‡§Ü‡§§‡•ç‡§Æ‡§æ ‡§ï‡•ã ‡§∂‡•ç‡§∞...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@firki07 firki queen üò≠  sc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@tuckercarlson called great britain looted 45 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content\n",
       "0                    nice night trip uk delhi. üòçüòçüòç  \n",
       "1  may soul rip. nation family fellow uk citizens...\n",
       "2  @sanjayazadsln ‡§Ö‡§§‡•ç‡§Ø‡§Ç‡§§ ‡§¶‡•Å‡§ñ‡§¶ ‡§¶‡§ø‡§µ‡§Ç‡§ó‡§§ ‡§Ü‡§§‡•ç‡§Æ‡§æ ‡§ï‡•ã ‡§∂‡•ç‡§∞...\n",
       "3                         @firki07 firki queen üò≠  sc\n",
       "4  @tuckercarlson called great britain looted 45 ..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. Removing URLs\n",
    "def remove_URLS(content):\n",
    "    return re.sub('((www.[^s]+)|(https?://[^s]+))',' ', str(content))\n",
    "\n",
    "df['content'] = df['content'].apply(lambda content: remove_URLS(content=content))\n",
    "#df['content'].head()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nice night trip uk delhi. üòçüòçüòç</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>may soul rip. nation family fellow uk citizens...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>‡§Ö‡§§‡•ç‡§Ø‡§Ç‡§§ ‡§¶‡•Å‡§ñ‡§¶ ‡§¶‡§ø‡§µ‡§Ç‡§ó‡§§ ‡§Ü‡§§‡•ç‡§Æ‡§æ ‡§ï‡•ã ‡§∂‡•ç‡§∞‡•Ä ‡§ö‡§∞‡§£‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§â...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>firki queen üò≠  sc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>called great britain looted 45 trillion usd ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content\n",
       "0                    nice night trip uk delhi. üòçüòçüòç  \n",
       "1  may soul rip. nation family fellow uk citizens...\n",
       "2    ‡§Ö‡§§‡•ç‡§Ø‡§Ç‡§§ ‡§¶‡•Å‡§ñ‡§¶ ‡§¶‡§ø‡§µ‡§Ç‡§ó‡§§ ‡§Ü‡§§‡•ç‡§Æ‡§æ ‡§ï‡•ã ‡§∂‡•ç‡§∞‡•Ä ‡§ö‡§∞‡§£‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§â...\n",
       "3                                  firki queen üò≠  sc\n",
       "4    called great britain looted 45 trillion usd ..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. Removing @mentions\n",
    "def remove_mentions(content):\n",
    "    return re.sub('(@\\S+)',' ', str(content))\n",
    "\n",
    "df['content'] = df['content'].apply(lambda content: remove_mentions(content=content))\n",
    "#df['content'].head()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nice night trip uk delhi. üòçüòçüòç</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>may soul rip. nation family fellow uk citizens...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>‡§Ö‡§§‡•ç‡§Ø‡§Ç‡§§ ‡§¶‡•Å‡§ñ‡§¶ ‡§¶‡§ø‡§µ‡§Ç‡§ó‡§§ ‡§Ü‡§§‡•ç‡§Æ‡§æ ‡§ï‡•ã ‡§∂‡•ç‡§∞‡•Ä ‡§ö‡§∞‡§£‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§â...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>firki queen üò≠  sc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>called great britain looted  trillion usd in...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content\n",
       "0                    nice night trip uk delhi. üòçüòçüòç  \n",
       "1  may soul rip. nation family fellow uk citizens...\n",
       "2    ‡§Ö‡§§‡•ç‡§Ø‡§Ç‡§§ ‡§¶‡•Å‡§ñ‡§¶ ‡§¶‡§ø‡§µ‡§Ç‡§ó‡§§ ‡§Ü‡§§‡•ç‡§Æ‡§æ ‡§ï‡•ã ‡§∂‡•ç‡§∞‡•Ä ‡§ö‡§∞‡§£‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§â...\n",
       "3                                  firki queen üò≠  sc\n",
       "4    called great britain looted  trillion usd in..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5. Removing numbers\n",
    "def remove_numericals(content):\n",
    "        return re.sub('[0-9]+', '', content)\n",
    "\n",
    "df['content'] = df['content'].apply(lambda content: remove_numericals(content=content))\n",
    "#df['content'].head()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Punctuation list:\n",
      "------------------\n",
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nice night trip uk delhi üòçüòçüòç</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>may soul rip nation family fellow uk citizens ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>‡§Ö‡§§‡•ç‡§Ø‡§Ç‡§§ ‡§¶‡•Å‡§ñ‡§¶ ‡§¶‡§ø‡§µ‡§Ç‡§ó‡§§ ‡§Ü‡§§‡•ç‡§Æ‡§æ ‡§ï‡•ã ‡§∂‡•ç‡§∞‡•Ä ‡§ö‡§∞‡§£‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§â...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>firki queen üò≠  sc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>called great britain looted  trillion usd in...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content\n",
       "0                     nice night trip uk delhi üòçüòçüòç  \n",
       "1  may soul rip nation family fellow uk citizens ...\n",
       "2    ‡§Ö‡§§‡•ç‡§Ø‡§Ç‡§§ ‡§¶‡•Å‡§ñ‡§¶ ‡§¶‡§ø‡§µ‡§Ç‡§ó‡§§ ‡§Ü‡§§‡•ç‡§Æ‡§æ ‡§ï‡•ã ‡§∂‡•ç‡§∞‡•Ä ‡§ö‡§∞‡§£‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§â...\n",
       "3                                  firki queen üò≠  sc\n",
       "4    called great britain looted  trillion usd in..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6. Removing punctuations\n",
    "PUNCTUATIONS = string.punctuation\n",
    "print('Punctuation list:')\n",
    "print('------------------')\n",
    "print(PUNCTUATIONS)\n",
    "\n",
    "def remove_punctuations(content):\n",
    "    return str(content).translate(str.maketrans('', '', PUNCTUATIONS))\n",
    "\n",
    "df['content'] = df['content'].apply(lambda content: remove_punctuations(content=content))\n",
    "# df['content'].head()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df.colA.map(lambda x: x.isascii())]\n",
    "\n",
    "df1=df.copy()\n",
    "# df1['DB_user'].str.encode('ascii', 'ignore').str.decode('ascii')\n",
    "# df1['new'] = df1['content'].apply(lambda content: content.encode('ascii', 'ignore').str.decode('ascii'))\n",
    "# df1.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nice night trip delhi üòçüòçüòç</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>may soul rip nation family fellow citizens mom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>‡•ç‡§Ç ‡•Å ‡§ø‡§Ç ‡•ç‡§æ ‡•ã ‡•ç‡•Ä ‡§ö‡§∞‡§£‡•ã‡§Ç ‡•á‡§Ç ‡•ç ‡•ç‡§æ ‡§ø‡•á ‡§ø‡§æ ‡•ã ‡•Ä ‡•Å ‡•á‡•á ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>firki queen üò≠</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>called great britain looted trillion usd india</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content\n",
       "0                         nice night trip delhi üòçüòçüòç \n",
       "1  may soul rip nation family fellow citizens mom...\n",
       "2   ‡•ç‡§Ç ‡•Å ‡§ø‡§Ç ‡•ç‡§æ ‡•ã ‡•ç‡•Ä ‡§ö‡§∞‡§£‡•ã‡§Ç ‡•á‡§Ç ‡•ç ‡•ç‡§æ ‡§ø‡•á ‡§ø‡§æ ‡•ã ‡•Ä ‡•Å ‡•á‡•á ...\n",
       "3                                     firki queen üò≠ \n",
       "4    called great britain looted trillion usd india "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7. Removing 2 letter random words, as it gives no meaning\n",
    "def remove_2letter_words(content):\n",
    "    w = w = re.sub(r'\\b\\w{1,2}\\b', '', content)\n",
    "    return re.sub(' +', ' ', w)\n",
    "\n",
    "df['content'] = df['content'].apply(lambda content: remove_2letter_words(content=content))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nice night trip delhi heart eyesüòçheart eyes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>may soul rip nation family fellow citizens mom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>‡•ç‡§Ç ‡•Å ‡§ø‡§Ç ‡•ç‡§æ ‡•ã ‡•ç‡•Ä ‡§ö‡§∞‡§£‡•ã‡§Ç ‡•á‡§Ç ‡•ç ‡•ç‡§æ ‡§ø‡•á ‡§ø‡§æ ‡•ã ‡•Ä ‡•Å ‡•á‡•á ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>firki queen sob</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>called great britain looted trillion usd india</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content\n",
       "0       nice night trip delhi heart eyesüòçheart eyes \n",
       "1  may soul rip nation family fellow citizens mom...\n",
       "2   ‡•ç‡§Ç ‡•Å ‡§ø‡§Ç ‡•ç‡§æ ‡•ã ‡•ç‡•Ä ‡§ö‡§∞‡§£‡•ã‡§Ç ‡•á‡§Ç ‡•ç ‡•ç‡§æ ‡§ø‡•á ‡§ø‡§æ ‡•ã ‡•Ä ‡•Å ‡•á‡•á ...\n",
       "3                                   firki queen sob \n",
       "4    called great britain looted trillion usd india "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 8. convert emoji to text\n",
    "def emoji_convert(content):\n",
    "    return kp_all_emoji_emoticons.replace_keywords(content)\n",
    "\n",
    "from emot.emo_unicode import UNICODE_EMOJI, UNICODE_EMOJI_ALIAS, EMOTICONS_EMO\n",
    "from flashtext import KeywordProcessor\n",
    "all_emoji_emoticons = {**EMOTICONS_EMO,**UNICODE_EMOJI_ALIAS, **UNICODE_EMOJI_ALIAS}\n",
    "all_emoji_emoticons = {k:v.replace(\":\",\"\").replace(\"_\",\" \").strip() for k,v in all_emoji_emoticons.items()}\n",
    "kp_all_emoji_emoticons = KeywordProcessor()\n",
    "for k,v in all_emoji_emoticons.items():\n",
    "    kp_all_emoji_emoticons.add_keyword(k, v)\n",
    "\n",
    "df['content'] = df['content'].apply(lambda content: emoji_convert(content=content))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nice night trip delhi heart eyesheart eyes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>may soul rip nation family fellow citizens mom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>n u in aa o ii crnnon en aa ie iaa o ii u ee i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>firki queen sob</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>called great britain looted trillion usd india</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content\n",
       "0         nice night trip delhi heart eyesheart eyes\n",
       "1  may soul rip nation family fellow citizens mom...\n",
       "2  n u in aa o ii crnnon en aa ie iaa o ii u ee i...\n",
       "3                                    firki queen sob\n",
       "4     called great britain looted trillion usd india"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 9. Remove unwanted emojis\n",
    "df['content'] = df['content'].apply(lambda content: clean(str(content), no_emoji=True))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\sarathkumar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nice night trip delhi heart eyesheart eyes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>may soul rip nation family fellow citizens mom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>crnnon iaa horrendous shame state acts happens...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>firki queen sob</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>called great britain looted trillion usd india</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content\n",
       "0         nice night trip delhi heart eyesheart eyes\n",
       "1  may soul rip nation family fellow citizens mom...\n",
       "2  crnnon iaa horrendous shame state acts happens...\n",
       "3                                    firki queen sob\n",
       "4     called great britain looted trillion usd india"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10. Removing meaningless words\n",
    "nltk.download('words')\n",
    "words = set(nltk.corpus.words.words())\n",
    "df['nonEnglish'] = df['content'].apply(lambda x: x.isascii() if isinstance(x, str) else False)\n",
    "df = df[df['nonEnglish'] == True]\n",
    "df = df.drop(['nonEnglish'], axis=1)\n",
    "df['content'] = df['content'].apply(lambda content: remove_2letter_words(content=content))\n",
    "df['content'] = df['content'].apply(lambda content: remove_stop_words(content=content))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('D:\\\\TCD\\\\Term1\\\\CS7CS4 - ML\\\\group project\\\\MachineLearning-group-project\\\\CleanedDatasets\\\\SouthAsia_Cleaned.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3ae812cea1838cfe625ef2ccd041db9e8a15742a5c13070da45ad927857ccd83"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
